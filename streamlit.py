from typing import Annotated, Sequence, TypedDict, Dict, List
import os
import json
from dotenv import load_dotenv
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, ToolMessage, SystemMessage, HumanMessage
from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from tools.vectordb_tool import KTDSVectorDBSearchTool
from tools.perplexity_tool import PerplexityQATool  # ìƒˆë¡œ ì¶”ê°€

load_dotenv()

# ì—ì´ì „íŠ¸ ìƒíƒœ ì •ì˜
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    chat_history: List[Dict[str, str]]

def create_qa_react_agent():
    """KT DS QA ReAct ì—ì´ì „íŠ¸ ìƒì„±"""
    # ê¸°ì¡´ KTDS VectorDB íˆ´
    qa_tool = KTDSVectorDBSearchTool()
    # ì¶”ê°€ Perplexity íˆ´
    perplexity_tool = PerplexityQATool()
    
    tools = [qa_tool, perplexity_tool]
    tools_by_name = {tool.name: tool for tool in tools}
    
    # ëª¨ë¸ ì„¤ì •
    model = ChatOpenAI(model="gpt-4o-mini")
    # ì—¬ëŸ¬ íˆ´ì„ ëª¨ë¸ì— ë°”ì¸ë”©
    model = model.bind_tools(tools)
    
    def tool_node(state: AgentState) -> Dict:
        """ë„êµ¬ ì‹¤í–‰ì„ ì²˜ë¦¬í•˜ëŠ” ë…¸ë“œ"""
        outputs = []
        last_msg = state["messages"][-1]
        
        if hasattr(last_msg, 'tool_calls'):
            for tool_call in last_msg.tool_calls:
                # tool_call["name"] ì´ ktds_qa_search í˜¹ì€ perplexity_qa_tool ì¼ ê²½ìš° í•´ë‹¹ íˆ´ì„ í˜¸ì¶œ
                tool_result = tools_by_name[tool_call["name"]].invoke(tool_call["args"])
                outputs.append(
                    ToolMessage(
                        content=tool_result,  # Dict í˜•íƒœë¡œ ë“¤ì–´ì˜¬ ìˆ˜ ìˆìŒ
                        name=tool_call["name"],
                        tool_call_id=tool_call["id"]
                    )
                )
        return {"messages": outputs, "chat_history": state["chat_history"]}

    def call_model(state: AgentState, config: RunnableConfig) -> Dict:
        """LLM í˜¸ì¶œ ë…¸ë“œ"""
        system_prompt = SystemMessage(content="""
        ë‹¹ì‹ ì€ KT DS QA ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        
        - ì‚¬ë‚´ ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸ì˜ ê²½ìš° ktds_qa_search(query, category)ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.
        - ì‚¬ë‚´ DBì—ì„œ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì–»ì§€ ëª»í–ˆê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´ perplexity_qa_tool(query)ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.
        - ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” hr, company, finance, product ì¹´í…Œê³ ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤.
        - ë„êµ¬ í˜¸ì¶œ ê²°ê³¼(ê²€ìƒ‰ ê²°ê³¼)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
        - ê²€ìƒ‰ ê²°ê³¼ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ë‹¤ë©´ "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”" ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
        """)

        all_messages = [system_prompt]
        all_messages.extend([
            HumanMessage(content=h["content"]) if h["role"] == "user" 
            else SystemMessage(content=h["content"]) 
            for h in state["chat_history"]
        ])
        all_messages.extend(state["messages"])
        
        response = model.invoke(all_messages, config)
        return {"messages": [response], "chat_history": state["chat_history"]}

    def should_continue(state: AgentState) -> str:
        """ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•˜ëŠ” ë…¸ë“œ"""
        last_msg = state["messages"][-1]
        
        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— tool_calls ê°€ ì¡´ì¬í•˜ê³ ,
        # ê·¸ ì•ˆì— ktds_qa_search ë˜ëŠ” perplexity_qa_tool ì´ ìˆë‹¤ë©´ 'continue' ë°˜í™˜
        if hasattr(last_msg, 'tool_calls') and any(
            call["name"] in ["ktds_qa_search", "perplexity_qa_tool"] for call in last_msg.tool_calls
        ):
            return "continue"
        
        return "end"
    
    # ê·¸ë˜í”„ êµ¬ì„±
    workflow = StateGraph(AgentState)
    workflow.add_node("agent", call_model)
    workflow.add_node("tools", tool_node)
    workflow.set_entry_point("agent")
    
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "continue": "tools",
            "end": END,
        },
    )
    workflow.add_edge("tools", "agent")
    
    return workflow.compile()

# Streamlit UI ì„¤ì •
st.set_page_config(
    page_title="KTDS QA",
    layout="centered",
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "agent" not in st.session_state:
    st.session_state.agent = create_qa_react_agent()
if "messages" not in st.session_state:
    st.session_state.messages = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
st.title("KTDS QA Assistant")
st.divider()

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì…ë ¥ì°½
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”!"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    st.chat_message("User").write(prompt)
    
    # ë‹µë³€ ìƒì„±
    with st.spinner("ğŸ¤– KTds QA ì—ì´ì „íŠ¸ê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆì–´ìš”..."):
        try:
            # ì‹¤ì œ ì²˜ë¦¬ ì‹œì‘
            response = st.session_state.agent.invoke({
                "messages": [HumanMessage(content=prompt)],
                "chat_history": st.session_state.chat_history
            })
           
            if response and "messages" in response:
                assistant_message = response["messages"][-1]
                assistant_content = assistant_message.content
                
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬
                st.session_state.messages.append({"role": "assistant", "content": assistant_content})
                st.session_state.chat_history.append({"role": "assistant", "content": assistant_content})
                
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            print(f"ì—ëŸ¬ ìƒì„¸: {e}")

    st.rerun()
